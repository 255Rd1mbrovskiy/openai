import os
import time
import asyncio
import logging
from collections import defaultdict, deque

from dotenv import load_dotenv
from telegram import Update, Message
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    ContextTypes, filters
)

# ---- OpenAI SDK (>=1.40.x) ----
from openai import OpenAI

# ------------------- CONFIG -------------------
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")   # Ð°Ð±Ð¾ "gpt-4.1-mini", Ð·Ð¼Ñ–Ð½ÑŽÐ¹ Ð½Ð° Ñ‰Ð¾ Ñ…Ð¾Ñ‡ÐµÑˆ

if not TELEGRAM_TOKEN:
    raise SystemExit("Set TELEGRAM_TOKEN")
if not OPENAI_API_KEY:
    raise SystemExit("Set OPENAI_API_KEY")

# Telegram
BOT_NAME = os.getenv("BOT_NAME", "AI Assistant")
MAX_HISTORY = int(os.getenv("MAX_HISTORY", "12"))        # ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ñ€ÐµÐ¿Ð»Ñ–Ðº Ð·Ð±ÐµÑ€Ñ–Ð³Ð°Ñ‚Ð¸ Ð½Ð° ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°
RATE_WINDOW = 10                                         # ÑÐµÐº
RATE_LIMIT = 5                                           # Ð½Ðµ Ð±Ñ–Ð»ÑŒÑˆÐµ N Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½ÑŒ Ð·Ð° RATE_WINDOW

# Ð›Ð¾Ð³ÑƒÐ²Ð°Ð½Ð½Ñ
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(name)s: %(message)s")
log = logging.getLogger("ai-bot")

# ------------------- STATE -------------------
client = OpenAI(api_key=OPENAI_API_KEY)

# Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ— Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½ÑŒ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñ–Ð²: user_id -> deque([{"role":"user/assistant","content":...}, ...])
histories: dict[int, deque] = defaultdict(lambda: deque(maxlen=MAX_HISTORY))
# Ð¿Ñ€Ð¾ÑÑ‚Ð¸Ð¹ rate-limit: user_id -> deque[timestamps]
rate: dict[int, deque] = defaultdict(lambda: deque(maxlen=RATE_LIMIT))

SYSTEM_PROMPT = (
    "You are a helpful, concise assistant. Answer in the same language the user uses. "
    "Avoid purple prose. If the user asks for code, provide runnable code."
)

# ------------------- HELPERS -------------------
def ratelimited(user_id: int) -> bool:
    now = time.time()
    dq = rate[user_id]
    # Ð²Ð¸Ð´Ð°Ð»ÑÑ”Ð¼Ð¾ ÑÑ‚Ð°Ñ€Ñ– Ð²Ñ–Ð´Ð¼Ñ–Ñ‚ÐºÐ¸
    while dq and now - dq[0] > RATE_WINDOW:
        dq.popleft()
    if len(dq) >= RATE_LIMIT:
        return True
    dq.append(now)
    return False

async def call_openai(messages: list[dict]) -> str:
    """
    Ð’Ð¸ÐºÐ»Ð¸Ðº OpenAI Responses API (Ð½Ðµ ÑÑ‚Ñ€Ñ–Ð¼Ð¸Ð¼Ð¾, Ñ‰Ð¾Ð± Ð±ÑƒÐ»Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÐµ).
    """
    resp = client.chat.completions.create(
        model=MODEL,
        messages=messages,
        temperature=0.6,
        max_tokens=700,
    )
    return resp.choices[0].message.content.strip()

async def reply_and_cleanup(msg: Message, text: str):
    try:
        await msg.reply_text(text, disable_web_page_preview=True)
    except Exception as e:
        log.warning("reply failed: %s", e)

# ------------------- HANDLERS -------------------
async def start_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        f"ðŸ‘‹ ÐŸÑ€Ð¸Ð²Ñ–Ñ‚! Ð¯ {BOT_NAME}.\n"
        "ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¿Ð¸ÑˆÐ¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ â€” Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð¼ ÑÐº Ð·Ð²Ð¸Ñ‡Ð°Ð¹Ð½Ð¸Ð¹ Ñ‡Ð°Ñ‚.\n\n"
        "ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸:\n"
        "â€¢ /reset â€” Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ñ‚Ð¸ Ñ–ÑÑ‚Ð¾Ñ€Ñ–ÑŽ Ð´Ñ–Ð°Ð»Ð¾Ð³Ñƒ\n"
        "â€¢ /model â€” Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñƒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n"
        "â€¢ /help â€” ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ° Ð´Ð¾Ð²Ñ–Ð´ÐºÐ°"
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await start_cmd(update, context)

async def model_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(f"ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ: `{MODEL}`", parse_mode="Markdown")

async def reset_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    histories.pop(uid, None)
    await update.message.reply_text("ðŸ§¹ Ð†ÑÑ‚Ð¾Ñ€Ñ–ÑŽ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð¾.")

async def chat_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.message is None or not update.message.text:
        return

    uid = update.effective_user.id
    text = update.message.text.strip()

    # Ð°Ð½Ñ‚Ð¸-Ñ„Ð»ÑƒÐ´
    if ratelimited(uid):
        await update.message.reply_text("â³ Ð—Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ñ‡Ð°ÑÑ‚Ð¾. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ Ñ‚Ñ€Ð¾Ñ…Ð¸ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ.")
        return

    # Ð±ÑƒÐ´ÑƒÑ”Ð¼Ð¾ Ñ–ÑÑ‚Ð¾Ñ€Ñ–ÑŽ Ð´Ð»Ñ OpenAI
    h = histories[uid]
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    messages.extend(list(h))
    messages.append({"role": "user", "content": text})

    # Ð²Ð¸ÐºÐ»Ð¸Ðº LLM
    try:
        answer = await call_openai(messages)
    except Exception as e:
        log.exception("openai error")
        await update.message.reply_text(f"âš ï¸ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸ÐºÐ»Ð¸ÐºÑƒ Ð¼Ð¾Ð´ÐµÐ»Ñ–: {e}")
        return

    # Ð¾Ð½Ð¾Ð²Ð»ÑŽÑ”Ð¼Ð¾ Ñ–ÑÑ‚Ð¾Ñ€Ñ–ÑŽ (Ñ‰Ð¾Ð± Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð¼Ð°Ð»Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚)
    h.append({"role": "user", "content": text})
    h.append({"role": "assistant", "content": answer})

    await reply_and_cleanup(update.message, answer)

# ------------------- MAIN -------------------
async def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", start_cmd))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("reset", reset_cmd))
    app.add_handler(CommandHandler("model", model_cmd))

    # Ð±ÑƒÐ´ÑŒ-ÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚ => Ð² Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat_handler))

    await app.initialize()
    await app.start()
    log.info("AI bot is polling â€¦")
    await app.updater.start_polling()
    await asyncio.Future()

if __name__ == "__main__":
    asyncio.run(main())
